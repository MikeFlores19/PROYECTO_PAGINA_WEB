<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>IA - Techno News!</title>
    <link rel="stylesheet" href="css/normalize.css">
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Bebas+Neue&family=Poppins:ital,wght@0,100;0,200;0,300;0,400;0,500;0,600;0,700;0,800;0,900;1,100;1,200;1,300;1,400;1,500;1,600;1,700;1,800;1,900&display=swap" rel="stylesheet">
    <link href="https://fonts.googleapis.com/css2?family=Bebas+Neue&display=swap" rel="stylesheet">
    <link rel="stylesheet" href="css/style.css">
</head>
<body>
    <header> 
        <h1 class="nombre-pagina">TECHNO <span>NEWS</span></h1>
    </header>
    <div class="container-nav">
        <nav class="nav-principal container">
            <a href="index.html">Inicio</a>
            <a href="index.html#noticias">Noticias</a>
            <a href="index.html#sobre_nosotros">Sobre Nosotros</a>
            <a href="index.html#contacto">Contacto</a>
        </nav>
    </div>
    <main class="container titulo">
        <div class="contenedor-padre">
            <div class="titulo-area-container">
                <h2>Inteligencia Artificial</h2>
            </div>
        </div>         
        <div class="seccion">
            <div class="titulo-container">
                <h3>Las pesimistas predicciones del FMI sobre los efectos de la IA en el empleo y la desigualdad</h3>
            </div>
            <p>La inteligencia artificial afectará a casi el 40% de todos los puestos de trabajo, según un nuevo análisis del Fondo Monetario Internacional (FMI).</p>
            <p>La directora gerente del FMI, Kristalina Georgieva, dice que "en la mayoría de los escenarios, la IA probablemente empeorará la desigualdad general".</p>
            <p>Georgieva añade que los legisladores deben abordar esa "preocupante tendencia" para "evitar que la tecnología avive aún más las tensiones sociales".</p>
            <p>La proliferación de la IA ha puesto de relieve sus beneficios y riesgos.</p>
            <p>En la mitad de estos casos, los trabajadores podrían esperar beneficiarse de la integración de la IA, lo que mejorará su productividad.</p>  
            <p>En otros casos, la IA tendrá la capacidad de realizar tareas clave que actualmente ejecutan los humanos. Esto podría reducir la demanda de mano de obra, afectando los salarios e incluso erradicando puestos de trabajo.</p>
            <div class="centered-figure">
                <img src="img/chatgpt.jpg" alt="Imagen chatgpt">
                <figcaption>La IA es un tema de debate tras el aumento en la popularidad de aplicaciones como ChatGPT</figcaption>
            </div>
            <h4>Riesgo de “empeorar la desigualdad”</h4>
            <p>Mientras tanto, el FMI proyecta que la tecnología afectará sólo al 26% de los empleos en los países de bajos ingresos.</p>
            <p>Se hace eco de un informe de Goldman Sachs de 2023, que estimaba que la IA podría reemplazar el equivalente a 300 millones de puestos de trabajo de tiempo completo, pero decía que también podría haber nuevos empleos junto con un auge de la productividad.Georgieva señaló que "muchos países no tienen la infraestructura o la fuerza laboral calificada para aprovechar los beneficios de la IA, lo que aumenta el riesgo de que con el tiempo la tecnología pueda empeorar la desigualdad entre las naciones".</p>
            <p>En términos más generales, los trabajadores más jóvenes y de mayores ingresos pueden ver un aumento desproporcionado en sus salarios después de adoptar la IA.</p>
            <p>El FMI cree que los trabajadores de menores ingresos y de mayor edad podrían quedarse atrás.</p>
            <p>La tecnología se enfrenta a cada vez más regulaciones en todo el mundo. El mes pasado, funcionarios de la Unión Europea llegaron a un acuerdo provisional sobre las primeras leyes integrales del mundo para regular el uso de la IA.</p>
            <p>El Parlamento Europeo votará las propuestas de la Ley de IA a principios de este año, pero ninguna legislación entrará en vigor al menos hasta 2025.</p>
            <p>Estados Unidos, Reino Unido y China aún tienen que publicar sus propias directrices sobre IA.</p>
        </div>
        <div class="seccion">
            <div class="titulo-container">
            <h3>Elon Musk afirma que la Inteligencia Artificial terminará con los empleos</h3>
            </div>
            <p>Elon Musk dice que la inteligencia artificial nos quitará el trabajo y que eso no es necesariamente malo. "Probablemente ninguno de nosotros tendrá trabajo", dijo Musk sobre la inteligencia artificial en una conferencia tecnológica el jueves.</p>
            <p>"Si quieres hacer un trabajo que sea algo así como un hobby, puedes hacer un trabajo", dijo Musk. "Pero por lo demás, la inteligencia artificial y los robots te proporcionarán los bienes y servicios que quieras".</p>
            <p>Para que este escenario funcione, dijo, tendría que haber una "renta alta universal", que no debe confundirse con la renta básica universal, aunque no compartió las características que podría tener. ("Renta básica universal" se refiere a que el gobierno dé una cierta cantidad de dinero a todo el mundo independientemente de cuánto gane). "No habría escasez de bienes ni de servicios", afirmó.</p>
            <div class="centered-figure">
                <img src="img/elonmuskia.jpg" alt="Imagen Elon Musk">
            </div>
            <p>Las capacidades de la inteligencia artificial han aumentado en los últimos años a un ritmo tan rápido que los reguladores, las empresas y los consumidores aún no saben cómo utilizar la tecnología de forma responsable. También sigue aumentando la preocupación por cómo cambiarán diversos sectores y puestos de trabajo a medida que la IA prolifere en el mercado.</p>
            <p>En enero, investigadores del Laboratorio de Ciencias de la Computación e Inteligencia Artificial del MIT descubrieron que los lugares de trabajo están adoptando la IA mucho más lentamente de lo que algunos esperaban y temían. El informe también señalaba que la mayoría de los empleos identificados previamente como vulnerables a la IA no eran económicamente beneficiosos para los empresarios que los automatizaran en ese momento.</p>
            <p>Los expertos también creen en gran medida que muchos empleos que requieren una gran inteligencia emocional e interacción humana no necesitarán ser sustituidos, como los profesionales de la salud mental, los creativos y los profesores.</p>
            <p>Musk ha manifestado abiertamente su preocupación por la IA. Durante la conferencia del jueves, calificó esta tecnología como su mayor temor. Citó la serie "Culture Book Series" de Ian Banks, una visión utópica ficticia de una sociedad dirigida por tecnología avanzada, como la más realista y "la mejor visión de una inteligencia artificial futura".</p>
            <p>Sin embargo, en un futuro sin trabajo, Musk se preguntó si la gente se sentiría realizada emocionalmente.</p>
            <p>"Si la computadora y los robots pueden hacer todo mejor que tú, ¿tiene sentido tu vida?", dijo. "Creo que los seres humanos aún tenemos un papel que desempeñar en este sentido, ya que podemos dar sentido a la inteligencia artificial".</p>
            <p>También utilizó su tiempo en el escenario para instar a los padres a limitar la cantidad de redes sociales que los niños pueden ver porque "están siendo programados por una inteligencia artificial que maximiza la dopamina".</p>
        </div>
        <div class="seccion">
            <div class="titulo-container">
            <h3>La Eurocámara aprueba una ley histórica para regular la inteligencia artificial</h3>
            </div>
            <div class="centered-figure">
                <img src="img/reconocimiento.jpg" alt="Imagen reconocimiento">
                <figcaption>No se podrán usar imágenes faciales obtenidas por cámaras de vigilancia para crear bases de datos</figcaption>
            </div>
            <p>El Reglamento, acordado en las negociaciones con los Estados miembros en diciembre de 2023, fue respaldado por la Eurocámara con 523 votos a favor, 46 en contra y 49 abstenciones.</p>
            <p>Su objetivo es proteger los derechos fundamentales, la democracia, el Estado de derecho y la sostenibilidad medioambiental frente a la IA que entraña un alto riesgo, impulsando al mismo tiempo la innovación y erigiendo a Europa en líder del sector. El Reglamento fija una serie de obligaciones para la IA en función de sus riesgos potenciales y su nivel de impacto.</p>
            <p><b>Aplicaciones prohibidas</b></p>
            <p>Las nuevas normas prohíben ciertas aplicaciones de inteligencia artificial que atentan contra los derechos de la ciudadanía, como los sistemas de categorización biométrica basados en características sensibles y la captura indiscriminada de imágenes faciales de internet o grabaciones de cámaras de vigilancia para crear bases de datos de reconocimiento facial. También se prohibirán el reconocimiento de emociones en el lugar de trabajo y en las escuelas, los sistemas de puntuación ciudadana, la actuación policial predictiva (cuando se base únicamente en el perfil de una persona o en la evaluación de sus características) y la IA que manipule el comportamiento humano o explote las vulnerabilidades de las personas.</p>
            <p><b>Exenciones de las fuerzas de seguridad</b></p>
            <p>El uso de sistemas de identificación biométrica por parte de las fuerzas de seguridad queda prohibido a priori, salvo en situaciones muy concretas y bien definidas. Los sistemas de identificación biométrica «en tiempo real» solo se podrán emplear si se cumplen una serie de salvaguardias estrictas; por ejemplo, su uso se limita a un período y lugar específicos y cuenta con una autorización judicial o administrativa previa. Entre estos casos pueden figurar la búsqueda selectiva de una persona desaparecida o la prevención de un atentado terrorista. Recurrir a estos sistemas a posteriori se considera un uso de alto riesgo, que requiere autorización judicial al estar vinculado a un delito penal.</p>
            <p><b>Obligaciones para los sistemas de alto riesgo</b></p>
            <p>También se prevén obligaciones claras para otros sistemas de IA de alto riesgo (debido a que pueden ser muy perjudiciales para la salud, la seguridad, los derechos fundamentales, el medio ambiente, la democracia y el Estado de derecho). Algunos ejemplos de usos de alto riesgo de la IA son las infraestructuras críticas, la educación y la formación profesional, el empleo, los servicios públicos y privados esenciales (por ejemplo, la sanidad o la banca), determinados sistemas de las fuerzas de seguridad, la migración y la gestión aduanera, la justicia y los procesos democráticos (como influir en las elecciones). Estos sistemas deben evaluar y reducir los riesgos, mantener registros de uso, ser transparentes y precisos y contar con supervisión humana. Los ciudadanos y ciudadanas tendrán derecho a presentar reclamaciones sobre los sistemas de IA y a recibir explicaciones sobre las decisiones basadas en ellos que afecten a sus derechos.</p>
            <p><b>Requisitos de transparencia</b></p>
            <p>Los sistemas de IA de uso general y los modelos en los que se basan deben cumplir ciertos requisitos de transparencia, respetar la legislación de la UE sobre derechos de autor y publicar resúmenes detallados del contenido usado para entrenar sus modelos. Los modelos más potentes que podrían plantear riesgos sistémicos deberán cumplir requisitos adicionales, como realizar evaluaciones de los modelos, analizar y mitigar los riesgos sistémicos e informar sobre los incidentes.</p>
            <p>Además, las imágenes, contenidos de audio o de vídeo artificiales o manipulados («ultrafalsificaciones») deberán etiquetarse claramente como tales.</p>
            <p><b>Medidas de apoyo a la innovación y a las pymes</b></p>
            <p>Habrá que poner a disposición de las pymes y de las empresas emergentes espacios controlados de pruebas y ensayos en condiciones reales a nivel nacional para que puedan desarrollar y entrenar la IA innovadora antes de su comercialización.</p>
        </div>
        <div class="seccion">
            <div class="titulo-container">
            <h3>Apple planea alianza con creadores de ChatGTP</h3>
            </div>
            <p>Apple ha retomado el contacto con la desarrolladora de la herramienta de Inteligencia Artificial (IA) generativa ChatGPT, OpenAI, para implementar funciones basadas en esta tecnología en su próximo modelo de iPhone.</p>
            <p>La compañía lleva meses planeando el despliegue de características impulsadas por IA en sus teléfonos y ya ha comenzado a negociar con Google la incorporación de Gemini mediante actualizaciones de ‘software’ a finales de este año.</p>
            <p>Las dos tecnológicas habrían comenzado a discutir los términos de un posible acuerdo y cómo se integrarían las características de OpenAI en la próxima iteración de su sistema operativo para móviles, iOS 18, según personas conocedoras de este pacto.</p>
            <p>El periodista Mark Gurman ha recordado en este adelanto que el próximo sistema operativo de iPhone incluirá varias características basadas en el modelo de lenguaje grande (LLM, por sus siglas en inglés) de Apple.</p>
            <div class="centered-figure">
                <img src="img/iphone.webp" alt="Imagen Iphone">
            </div>
            <p>Entre los colaboradores con los que Apple también habría establecido contacto se encuentra la ‘startup’ de IA Anthropic, desarrolladora de los modelos de IA generativa Claude 3 Haiku, Claude 3 Sonnet y Claude 3 Opus.</p>
            <p><b>Apple baraja presentar un iPad Pro con chip M4</b></p>
            <p>Apple se plantea integrar en la tableta iPad Pro un chip M4 en lugar de esperar a los ordenadores Mac para hacer debutar este modelo de procesador propio, dando así el salto a la nueva era de la inteligencia artificial (IA) antes incluso de su evento anual de desarrolladores (WWDC 2024).</p>
            <p>La tableta iPad Pro, en lugar de funcionar con un chip M3, integraría un procesador M4, dotado de un nuevo motor neuronal, diseñado para impulsar las aplicaciones con IA, según ha compartido el analista de Apple y periodista de Bloomberg, Mark Gurman, en su boletón ‘Power On’.</p>
            <div class="centered-figure">
                <img src="img/ipad.avif" alt="Imagen Ipad">
                <figcaption>Modelos de iPad Pro de 11 y 12,9 pulgadas</figcaption>
            </div>
            <p>Esta incursión en los dispositivos IA precedería a la explicación oficial y más detalla de la estrategia de la compañía con esta tecnología en el marco de WWDC 2024, que se celebrará en junio, y permitiría tener disponible un equipo dotado con el soporte necesario para aprovechar las nuevas capacidades de IA que llegarán más adelante con iPadOS 18.</p>
        </div>
        <div class="seccion">
            <div class="titulo-container">
            <h3>OpenAI abre por primera vez la puerta al ejército y el uso militar de su IA</h3>
            </div>
            <p>Una de las mayores preocupaciones que existen en torno a la inteligencia artificial tiene que ver con su inminente uso en el sector militar. Este último se encuentra en una búsqueda constante de nuevas tecnologías que les otorguen ventajas en el campo de batalla, así que la IA eventualmente se convertirá en un aliado clave. En OpenAI saben que ellos pueden ser un socio para las fuerzas armadas de diversos países, y no piensan desaprovecharlo.</p>
            <p>Según la información de The Intercept, el pasado  enero actualizaron sus políticas para retirar esa exclusión.</p>
            <p>Evidentemente, en OpenAI optaron por hacer el menor ruido posible con este importante cambio. ¿Por qué? Porque es polémico. No obstante, tarde o temprano se iba a descubrir.</p>
            <p>El citado medio se puso en contacto con OpenAI para obtener más información al respecto. En la compañía consideran que, en lugar de usar las palabras "militar y guerra", es más prudente prohibir la utilización de su inteligencia artificial para "dañar a otros". El problema es que esta frase puede tener un significado bastante amplio y no cierra la puerta, como antes, a que se use en la guerra con distintos fines.</p>
            <p>Con relación al momento en que realizaron esta modificación a sus normas, OpenAI afirma que se debe el reciente lanzamiento de GPTs. Es decir, la posibilidad de que la gente puede crear sus propios chatbots sin tener conocimientos avanzados en programación. En consecuencia, vieron conveniente transmitir a los usuarios que no pueden crear una herramienta para perjudicar a otros.</p>
            <p>Al final, en un comunicado compartido con Endgadget, OpenAI reconoció que ya se encuentran trabajando con la Agencia de Proyectos de Investigación Avanzados de Defensa (DARPA, por sus siglas en inglés), un organismo que pertenece al Departamento de Defensa de Estados Unidos y cuyo propósito es desarrollar nuevas tecnologías para su uso militar.</p>
            <p>"Nuestra política no permite que nuestras herramientas se utilicen para dañar a las personas, desarrollar armas, vigilar las comunicaciones, herir a otros o destruir propiedades. Sin embargo, existen casos de uso de seguridad nacional que se alinean con nuestra misión.</p>
            <p>Por ejemplo, ya estamos trabajando con DARPA para impulsar la creación de nuevas herramientas de ciberseguridad para proteger el software de código abierto del que depende su infraestructura crítica. No estaba claro si estos casos de uso beneficiosos se habrían permitido bajo el término "militar" en nuestras políticas anteriores. Por lo tanto, el objetivo de nuestra actualización es brindar claridad y la capacidad de tener estas discusiones." OpenAI </p>
            <p>Sin duda, se liaron demasiado con el tema. Solo tenían que reconocer y enfatizar, desde un principio, que cambiaron su política para poder trabajar con gobiernos y obtener contratos multimillonarios.</p>
            <div class="centered-figure">
            <img src="img/militar.jpg" alt="Imagen militar">
            <figcaption>Militar captado con perro róbotico movido por IA</figcaption>
            </div>
        </div>
    </main>
    <footer>
        <p>Todos los derechos reservados. Technonews</p>
    </footer>
</body>
</html>